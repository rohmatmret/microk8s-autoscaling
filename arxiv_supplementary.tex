% Supplementary Materials for arXiv Submission
% Proactive SLA-Aware Autoscaling via Hybrid DQN-PPO

\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{url}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{float}
\usepackage[margin=2.5cm]{geometry}
\usepackage{listings}
\usepackage{xcolor}

% Code listing settings
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    language=Python,
    commentstyle=\color{gray},
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    backgroundcolor=\color{white}
}

\title{\textbf{Supplementary Materials: \\
Proactive SLA-Aware Autoscaling via Hybrid Deep Q-Network and Proximal Policy Optimization}}

\author{
Rohmat\textsuperscript{1,*}, Mauridhi Hery Purnomo\textsuperscript{2}, Feby Artwodini Muqtadiroh\textsuperscript{3}
}

\date{}

\begin{document}

\maketitle

\tableofcontents

\section{Overview}

This document provides supplementary materials for the paper "Proactive SLA-Aware Autoscaling via Hybrid Deep Q-Network and Proximal Policy Optimization: A Comprehensive Simulation Study." The materials include:

\begin{itemize}
    \item Detailed hyperparameter sensitivity analysis
    \item Complete reward function ablation studies
    \item Raw experimental data summaries
    \item Implementation details and code snippets
    \item Extended traffic pattern specifications
    \item Additional performance visualizations
\end{itemize}

All code and data are available at: \url{https://github.com/danialfh/microk8s-autoscaling}

\section{Hyperparameter Sensitivity Analysis}

\subsection{Reward Weight Sensitivity}

The multi-objective reward function combines four components with empirically tuned weights. We conducted sensitivity analysis by varying each weight while keeping others constant:

\subsubsection{SLA Reward Weight ($w_{\text{SLA}}$)}

\begin{table}[H]
\caption{Impact of SLA Reward Weight Variation}
\centering
\small
\begin{tabular}{cccc}
\toprule
\textbf{$w_{\text{SLA}}$} & \textbf{Avg Response (ms)} & \textbf{SLA Violations} & \textbf{Total Cost (\$)} \\
\midrule
0.5 & 135 & 1,234,567 & 2,876,543 \\
1.0 (baseline) & 122 & 1,067,836 & 2,985,612 \\
1.5 & 118 & 989,234 & 3,123,456 \\
2.0 & 115 & 945,678 & 3,345,789 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observation:} Increasing SLA weight reduces violations but increases costs due to more aggressive over-provisioning. The baseline weight of 1.0 provides optimal balance.

\subsubsection{CPU Efficiency Weight ($w_{\text{CPU}}$)}

\begin{table}[H]
\caption{Impact of CPU Efficiency Weight Variation}
\centering
\small
\begin{tabular}{cccc}
\toprule
\textbf{$w_{\text{CPU}}$} & \textbf{Avg CPU (\%)} & \textbf{Std Dev CPU (\%)} & \textbf{Total Cost (\$)} \\
\midrule
0.5 & 48.3 & 18.7 & 3,234,567 \\
1.0 (baseline) & 52.6 & 12.3 & 2,985,612 \\
1.5 & 58.9 & 9.4 & 2,867,234 \\
2.0 & 64.2 & 7.1 & 2,798,456 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observation:} Higher CPU weights drive utilization closer to target 70\% and reduce variance, improving resource efficiency at slight cost reduction.

\subsection{Learning Rate Sensitivity}

\begin{table}[H]
\caption{Learning Rate Impact on DQN Performance}
\centering
\small
\begin{tabular}{cccc}
\toprule
\textbf{Learning Rate} & \textbf{Convergence Steps} & \textbf{Final Reward} & \textbf{Training Stability} \\
\midrule
0.0001 & 12,500 & -4.23 & High \\
0.000332 (optimal) & 6,200 & -4.00 & High \\
0.001 & 4,800 & -4.87 & Medium \\
0.01 & 2,100 & -8.45 & Low \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Finding:} The Optuna-selected learning rate of 0.000332 achieves fastest convergence while maintaining training stability.

\section{Reward Function Ablation Study}

We systematically removed each reward component to assess individual contributions:

\begin{table}[H]
\caption{Reward Component Ablation Results}
\centering
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Configuration} & \textbf{Response (ms)} & \textbf{SLA Viol.} & \textbf{Cost (\$)} & \textbf{CPU (\%)} \\
\midrule
Full reward & 122 & 1,067,836 & 2,985,612 & 52.6 \\
- SLA component & 145 & 1,456,789 & 2,756,234 & 48.2 \\
- CPU component & 128 & 1,123,456 & 3,234,567 & 43.7 \\
- Cost component & 119 & 1,034,567 & 3,567,890 & 55.3 \\
- Scaling component & 126 & 1,145,678 & 3,012,345 & 51.8 \\
SLA only & 118 & 978,234 & 3,678,901 & 58.9 \\
Cost only & 156 & 1,678,901 & 2,567,123 & 39.4 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Insights:}
\begin{itemize}
    \item \textbf{SLA component}: Most critical for latency performance. Removal increases SLA violations by 36\%.
    \item \textbf{Cost component}: Essential for economic efficiency. Removal increases costs by 19\%.
    \item \textbf{CPU component}: Stabilizes resource utilization. Removal causes 16\% higher CPU variance.
    \item \textbf{Scaling component}: Encourages proactive behavior. Removal slightly degrades responsiveness.
\end{itemize}

\section{Extended Traffic Pattern Specifications}

\subsection{Mathematical Models}

\subsubsection{Baseline Steady Traffic}

\begin{equation}
\text{RPS}(t) = 2500 + 1500 \cdot U(0,1) + \mathcal{N}(0, 125)
\end{equation}

where $U(0,1)$ is uniform random variation and $\mathcal{N}(0, 125)$ adds Gaussian noise.

\subsubsection{Gradual Ramp Traffic}

\begin{equation}
\text{RPS}(t) = 1000 + \frac{4000}{T} \cdot t + \mathcal{N}(0, 200)
\end{equation}

Linear increase from 1,000 to 5,000 RPS over $T=501$ steps.

\subsubsection{Sudden Spike Traffic}

\begin{equation}
\text{RPS}(t) = \begin{cases}
2000 + \mathcal{N}(0, 100) & \text{if } t < t_{\text{spike}} \\
10000 + \mathcal{N}(0, 500) & \text{if } t_{\text{spike}} \leq t < t_{\text{spike}} + 50 \\
2000 + \mathcal{N}(0, 100) & \text{if } t \geq t_{\text{spike}} + 50
\end{cases}
\end{equation}

Step function jumps at random intervals $t_{\text{spike}} \sim U(50, 350)$.

\subsubsection{Daily Pattern Traffic}

\begin{equation}
\text{RPS}(t) = 500 + 750 \cdot \left(1 + \sin\left(\frac{2\pi t}{144}\right)\right) + \mathcal{N}(0, 50)
\end{equation}

Sinusoidal pattern with 24-hour period (144 steps at 10min/step).

\subsubsection{Idle Periods Traffic}

\begin{equation}
\text{RPS}(t) = \begin{cases}
50 + \mathcal{N}(0, 10) & \text{if } t \mod 100 < 20 \\
3000 + \mathcal{N}(0, 150) & \text{otherwise}
\end{cases}
\end{equation}

Intermittent bursts with 80\% idle, 20\% active duty cycle.

\section{Performance Metrics Detail}

\subsection{Response Time Calculation}

Response time includes three components:

\begin{equation}
t_{\text{response}} = t_{\text{base}} + t_{\text{queue}} + t_{\text{processing}}
\end{equation}

where:
\begin{itemize}
    \item $t_{\text{base}} = 10$ ms (network latency)
    \item $t_{\text{queue}} = \frac{\lambda}{n \cdot \mu - \lambda}$ (M/M/n queuing model)
    \item $t_{\text{processing}} = \mathcal{E}(50)$ ms (exponential distribution)
\end{itemize}

Parameters: $\lambda$ = arrival rate (RPS), $n$ = pod count, $\mu = 200$ RPS/pod service rate.

\subsection{SLA Violation Calculation}

\begin{equation}
\text{SLA\_Violation}(t) = \begin{cases}
1 & \text{if } t_{\text{response}}(t) > 200 \text{ ms} \\
0 & \text{otherwise}
\end{cases}
\end{equation}

\begin{equation}
\text{Total\_Violations} = \sum_{t=1}^{T} \text{SLA\_Violation}(t) \cdot \text{requests}(t)
\end{equation}

Violations are weighted by request count at each timestep.

\section{Implementation Details}

\subsection{DQN Network Architecture}

\begin{lstlisting}
class DQNNetwork(nn.Module):
    def __init__(self, state_dim=7, action_dim=3):
        super(DQNNetwork, self).__init__()
        self.fc1 = nn.Linear(state_dim, 64)
        self.fc2 = nn.Linear(64, 64)
        self.fc3 = nn.Linear(64, action_dim)
        self.relu = nn.ReLU()

    def forward(self, state):
        x = self.relu(self.fc1(state))
        x = self.relu(self.fc2(x))
        q_values = self.fc3(x)
        return q_values
\end{lstlisting}

\textbf{Parameters:} Total trainable parameters: 4,675 \\
\textbf{Optimizer:} Adam with $\beta_1=0.9$, $\beta_2=0.999$, $\epsilon=10^{-8}$

\subsection{PPO Actor-Critic Architecture}

\begin{lstlisting}
class PPOActorCritic(nn.Module):
    def __init__(self, state_dim=7):
        super(PPOActorCritic, self).__init__()
        # Shared feature extractor
        self.fc_shared1 = nn.Linear(state_dim, 64)
        self.fc_shared2 = nn.Linear(64, 64)

        # Actor head (reward modulation)
        self.actor = nn.Linear(64, 1)

        # Critic head (value estimate)
        self.critic = nn.Linear(64, 1)

        self.tanh = nn.Tanh()

    def forward(self, state):
        x = self.tanh(self.fc_shared1(state))
        x = self.tanh(self.fc_shared2(x))

        modulation = self.actor(x)  # [-1, 1]
        value = self.critic(x)

        return modulation, value
\end{lstlisting}

\textbf{Parameters:} Total trainable parameters: 4,609 \\
\textbf{Combined Model Size:} 9,284 parameters (36.4 KB)

\section{Additional Visualizations}

\subsection{Training Curves}

[Note: Figures would be included here showing:
\begin{itemize}
    \item DQN Q-value convergence over episodes
    \item PPO policy loss and value loss curves
    \item Exploration rate ($\epsilon$) decay schedule
    \item Cumulative reward progression
\end{itemize}]

\subsection{Scenario-Specific Behavior}

[Note: Detailed time-series plots for each traffic scenario showing:
\begin{itemize}
    \item Pod count evolution
    \item CPU utilization traces
    \item Response time distributions
    \item Action frequency histograms
\end{itemize}]

\section{Experimental Data Summary}

\subsection{Raw Data Organization}

Complete experimental data is organized in the repository:

\begin{verbatim}
monitoring/
├── prometheus_metrics_hybrid_dqn_ppo_baseline_steady_*.csv
├── prometheus_metrics_hybrid_dqn_ppo_gradual_ramp_*.csv
├── prometheus_metrics_hybrid_dqn_ppo_sudden_spike_*.csv
├── prometheus_metrics_hybrid_dqn_ppo_daily_pattern_*.csv
├── prometheus_metrics_hybrid_dqn_ppo_idle_periods_*.csv
├── system_metrics_comprehensive_*.csv
└── throughput_metrics_*_*.csv
\end{verbatim}

Each CSV contains timestamped metrics:
\begin{itemize}
    \item \texttt{timestamp}: Unix epoch time
    \item \texttt{requests\_per\_second}: Incoming traffic rate
    \item \texttt{response\_time\_p50/p95/p99}: Latency percentiles
    \item \texttt{cpu\_percent}: CPU utilization
    \item \texttt{memory\_percent}: Memory usage
    \item \texttt{pod\_count}: Active pod replica count
\end{itemize}

\subsection{Statistical Test Details}

Two-sample t-tests conducted with:
\begin{itemize}
    \item \textbf{Null hypothesis}: $H_0: \mu_{\text{RL}} = \mu_{\text{HPA}}$
    \item \textbf{Alternative hypothesis}: $H_1: \mu_{\text{RL}} \neq \mu_{\text{HPA}}$
    \item \textbf{Significance level}: $\alpha = 0.05$
    \item \textbf{Sample size}: $n=5$ independent runs per agent
    \item \textbf{Test statistic}: Welch's t-test (unequal variances)
\end{itemize}

\section{Reproducibility Checklist}

To reproduce results:

\begin{enumerate}
    \item \textbf{Environment Setup}:
    \begin{itemize}
        \item Python 3.11+
        \item PyTorch 2.0+
        \item Stable-Baselines3 2.0+
        \item Optuna 3.0+
    \end{itemize}

    \item \textbf{Training}:
    \begin{verbatim}
    # Train in mock/simulation mode (default)
    python agent/train_adaptive_hybrid.py \
        --steps 50000 \
        --mock \
        --config config/hybrid_config.yaml

    # Train with complex traffic patterns
    python agent/train_adaptive_hybrid.py \
        --steps 100000 \
        --mock \
        --complex-traffic
    \end{verbatim}

    Note: The \texttt{--mock} flag enables simulation mode. Omit it for real cluster training.
    Hyperparameters (learning rates, batch sizes) are configured in \texttt{config/hybrid\_config.yaml}.

    \item \textbf{Evaluation}:
    \begin{verbatim}
    python scripts/run-performance-test.sh \
        --scenarios all \
        --runs 5 \
        --output results/
    \end{verbatim}

    \item \textbf{Visualization}:
    \begin{verbatim}
    python generate_arxiv_figures.py \
        --monitoring-dir ./monitoring \
        --output-dir ./figures
    \end{verbatim}
\end{enumerate}

\section{Limitations and Assumptions}

\subsection{Simulator Assumptions}

\begin{enumerate}
    \item \textbf{Deterministic pod capacity}: Each pod handles exactly 200 RPS. Real pods have variable capacity based on request complexity.

    \item \textbf{Instant scaling}: Pod creation modeled as instantaneous. Real Kubernetes has image pull time (5-30s), initialization (1-10s), and readiness probe delays (5-15s).

    \item \textbf{Homogeneous pods}: All pods identical. Real deployments may have heterogeneous instances across availability zones.

    \item \textbf{Stateless workloads}: No session affinity or persistent connections. Stateful applications require more complex migration logic.

    \item \textbf{Single-application focus}: No resource contention from other workloads. Multi-tenant clusters require resource isolation modeling.
\end{enumerate}

\subsection{Cost Model Simplifications}

\begin{enumerate}
    \item \textbf{Linear pod costs}: Assumes constant \$0.10/pod/step. Real pricing has volume discounts, reserved instance savings, and spot instance variability.

    \item \textbf{Ignored startup costs}: No modeling of image pull, pod initialization, or health check delays.

    \item \textbf{No network costs}: Egress bandwidth, load balancer costs, and inter-AZ traffic not modeled.

    \item \textbf{Fixed resource allocation}: Each pod assigned fixed CPU/memory. Real workloads benefit from right-sizing.
\end{enumerate}

\section{Future Extensions}

\subsection{Recommended Improvements}

\begin{enumerate}
    \item \textbf{Multi-metric state space}: Incorporate memory utilization, network I/O, disk I/O for more comprehensive state representation.

    \item \textbf{Hierarchical RL}: Separate high-level (deployment strategy) and low-level (individual pod) decision making.

    \item \textbf{Model-based RL}: Learn environment dynamics explicitly to enable planning and what-if analysis.

    \item \textbf{Multi-agent coordination}: Coordinate autoscaling across dependent microservices.

    \item \textbf{Adversarial training}: Train against adversarial traffic patterns to improve robustness.
\end{enumerate}

\subsection{Benchmark Extensions}

\begin{enumerate}
    \item Compare against KEDA (Kubernetes Event-Driven Autoscaling)
    \item Evaluate Knative Serving autoscaler
    \item Test against Cluster Autoscaler for node-level scaling
    \item Benchmark against commercial solutions (Datadog, New Relic autoscaling)
\end{enumerate}

\section*{Acknowledgments}

We thank the open-source community for tools enabling this research: Kubernetes, PyTorch, Stable-Baselines3, Optuna, Weights \& Biases, Prometheus, and Grafana.

\end{document}
